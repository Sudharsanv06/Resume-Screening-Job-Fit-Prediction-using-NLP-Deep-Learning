{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e43c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Scikit-learn for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586be53",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05282896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "X_train = np.load('../models/X_train.npy')\n",
    "X_test = np.load('../models/X_test.npy')\n",
    "y_train = np.load('../models/y_train.npy')\n",
    "y_test = np.load('../models/y_test.npy')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ab7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and label encoder\n",
    "with open('../models/tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "with open('../models/label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "print(\"âœ… Tokenizer and label encoder loaded!\")\n",
    "print(f\"\\nVocabulary size: {len(tokenizer.word_index) + 1}\")\n",
    "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"\\nJob categories: {list(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19673e1e",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical (one-hot encoding)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"âœ… Labels converted to categorical format!\")\n",
    "print(f\"y_train_cat shape: {y_train_cat.shape}\")\n",
    "print(f\"y_test_cat shape: {y_test_cat.shape}\")\n",
    "print(f\"\\nSample one-hot encoded label:\")\n",
    "print(f\"Original label: {y_train[0]}\")\n",
    "print(f\"One-hot encoded: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = X_train.shape[1]\n",
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"LSTM units: {lstm_units}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f0967",
   "metadata": {},
   "source": [
    "## 3. Build Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    # Embedding layer\n",
    "    Embedding(input_dim=vocab_size, \n",
    "              output_dim=embedding_dim, \n",
    "              input_length=max_length,\n",
    "              name='embedding'),\n",
    "    \n",
    "    # Bidirectional LSTM layer\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=False), name='bi_lstm'),\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    Dropout(0.5, name='dropout'),\n",
    "    \n",
    "    # Dense layer with ReLU activation\n",
    "    Dense(64, activation='relu', name='dense_relu'),\n",
    "    \n",
    "    # Output layer with Softmax activation\n",
    "    Dense(num_classes, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "print(\"âœ… Bi-LSTM model built successfully!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108ccc2",
   "metadata": {},
   "source": [
    "## 4. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled successfully!\")\n",
    "print(\"\\nCompilation details:\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: Categorical Crossentropy\")\n",
    "print(f\"Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca77b04d",
   "metadata": {},
   "source": [
    "## 5. Set up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712343ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    '../models/resume_classifier.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "print(\"âœ… Callbacks configured!\")\n",
    "print(\"- Early Stopping: Monitors val_loss with patience=3\")\n",
    "print(\"- Model Checkpoint: Saves best model based on val_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4e088",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"ðŸš€ Starting model training...\\n\")\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 4\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ae6da",
   "metadata": {},
   "source": [
    "## 7. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f82c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Training history plots saved to results/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7468a57",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6467cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"ðŸ“Š Evaluating model on test set...\\n\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(min(5, len(y_test))):\n",
    "    true_label = label_encoder.classes_[y_test[i]]\n",
    "    pred_label = label_encoder.classes_[y_pred[i]]\n",
    "    confidence = y_pred_probs[i][y_pred[i]] * 100\n",
    "    \n",
    "    match = \"âœ“\" if true_label == pred_label else \"âœ—\"\n",
    "    print(f\"{match} True: {true_label:20s} | Predicted: {pred_label:20s} | Confidence: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba10aff",
   "metadata": {},
   "source": [
    "## 9. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3440b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ebef6",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Resume Classification', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Confusion matrix saved to results/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98a63d",
   "metadata": {},
   "source": [
    "## 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('../models/resume_classifier.h5')\n",
    "print(\"âœ… Model saved to models/resume_classifier.h5\")\n",
    "\n",
    "# Also save in Keras format\n",
    "model.save('../models/resume_classifier.keras')\n",
    "print(\"âœ… Model saved to models/resume_classifier.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a0369",
   "metadata": {},
   "source": [
    "## 12. Save Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d07df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final training metrics\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "epochs_trained = len(history.history['accuracy'])\n",
    "\n",
    "# Create metrics text file\n",
    "metrics_text = f\"\"\"TRAINING METRICS - DAY 3\n",
    "====================================\n",
    "\n",
    "Model Information:\n",
    "- Model Type: Bidirectional LSTM\n",
    "- Architecture: Embedding â†’ Bi-LSTM â†’ Dropout â†’ Dense (ReLU) â†’ Dense (Softmax)\n",
    "- Embedding Dimension: {embedding_dim}\n",
    "- LSTM Units: {lstm_units}\n",
    "- Total Parameters: {model.count_params():,}\n",
    "\n",
    "Training Configuration:\n",
    "- Optimizer: Adam\n",
    "- Loss Function: Categorical Crossentropy\n",
    "- Batch Size: {batch_size}\n",
    "- Epochs Trained: {epochs_trained}/{epochs}\n",
    "- Validation Split: 20%\n",
    "\n",
    "Dataset:\n",
    "- Total Samples: {len(X_train) + len(X_test)}\n",
    "- Training Samples: {len(X_train)}\n",
    "- Testing Samples: {len(X_test)}\n",
    "- Number of Classes: {num_classes}\n",
    "- Vocabulary Size: {vocab_size}\n",
    "- Max Sequence Length: {max_length}\n",
    "\n",
    "Training Results:\n",
    "- Final Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\n",
    "- Final Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\n",
    "- Final Training Loss: {final_train_loss:.4f}\n",
    "- Final Validation Loss: {final_val_loss:.4f}\n",
    "\n",
    "Test Results:\n",
    "- Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\n",
    "- Test Loss: {test_loss:.4f}\n",
    "\n",
    "Model Files:\n",
    "- models/resume_classifier.h5\n",
    "- models/resume_classifier.keras\n",
    "- models/tokenizer.pkl\n",
    "- models/label_encoder.pkl\n",
    "\n",
    "Visualization Files:\n",
    "- results/training_history.png\n",
    "- results/confusion_matrix.png\n",
    "\n",
    "Job Categories:\n",
    "{chr(10).join(f'  {i+1}. {cat}' for i, cat in enumerate(label_encoder.classes_))}\n",
    "\n",
    "Ready for Day 4: Testing & Deployment!\n",
    "\"\"\"\n",
    "\n",
    "with open('../results/metrics.txt', 'w') as f:\n",
    "    f.write(metrics_text)\n",
    "\n",
    "print(\"âœ… Metrics saved to results/metrics.txt\")\n",
    "print(\"\\n\" + metrics_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83602ffb",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DAY 3 SUMMARY - DEEP LEARNING MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nâœ… Model Architecture: Bi-LSTM\")\n",
    "print(f\"   - Layers: Embedding â†’ Bi-LSTM â†’ Dropout â†’ Dense â†’ Output\")\n",
    "print(f\"   - Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nâœ… Training Complete:\")\n",
    "print(f\"   - Epochs: {epochs_trained}/{epochs}\")\n",
    "print(f\"   - Final Training Accuracy: {final_train_acc*100:.2f}%\")\n",
    "print(f\"   - Final Validation Accuracy: {final_val_acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nâœ… Test Performance:\")\n",
    "print(f\"   - Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   - Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ… Files Saved:\")\n",
    "print(f\"   - Model: models/resume_classifier.h5, models/resume_classifier.keras\")\n",
    "print(f\"   - Metrics: results/metrics.txt\")\n",
    "print(f\"   - Plots: results/training_history.png, results/confusion_matrix.png\")\n",
    "\n",
    "print(f\"\\nðŸš€ Ready for Day 4: Testing & Deployment!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
